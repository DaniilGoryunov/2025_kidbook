# Отчет по лабораторной работе

## Состав команды

| ФИО         | Что делал           | Оценка |
|-------------|----------------|--------|
| Епифанов Евгений Валерьевич | Работа со `SPARQL` |      |
| Салихов Тимур Русланович | Изучение предметной области, создание страниц |    |
| Эсмедляев Фёдор Романович | Формирование запросов, создание страниц |      |
| Головенко Анатолий Валерьевич | Взаимодействие с `LLM API Гигачат` |         |
| Куценко Максим Дмитриевич | Руководство, связывание кода и автоматизация генерации, отчётность |      |

## Концептуализация предметной области

Сначала мы изучили вручную что из себя представляет `Wikidata` и создали референсный граф с помощью `Wikidata Visualisation Tool`. Далее мы сначала написали простой запрос на `SPARQL`, потом поняли как создать граф и сформировали соответствующий запрос, выдающий результат в формате **id_объекта-название-определение-тип_связи-id_объекта-название-определение**, отфильтровали лишнюю информацию. После этого мы сделали обход графа начиная от его центра с формированием страниц.

Приложенный ноутбук ***автоматически*** создаёт для *указанного понятия* и *максимального числа связей* граф, отправляя `SPARQL`-запрос, формируя страницы со ссылками, concepts.json и онтологию в формате Mermaid.

Ниже указана онтология для *максимального числа связей* = 50.

```mermaid
classDiagram
  direction LR
  фильм --> сценарист : "P1963"
  фильм --> режиссёр : "P1963"
  фильм --> жанр : "P1963"
  режиссёр --> создатель : "P1659"
  фильм --> композитор : "P1963"
  фильм --> в_ролях : "P1963"
  фильм --> полученные_награды : "P1963"
  композитор --> автор_слов : "P1659"
  композитор --> оркестровщик : "P1659"
  фильм --> теория_кино : "P2579"
  фильм --> киноведение : "P2579"
  композитор --> создатель : "P1659"
  композитор --> автор_либретто : "P1659"
  композитор --> автор : "P1659"
  режиссёр --> автор : "P1659"
  жанр --> школа_-движение- : "P1659"
  фильм --> создано_на_основе : "P1963"
  фильм --> язык_оригинала_фильма_или_телешоу : "P1963"
  фильм --> является_частью_цикла : "P1963"
  в_ролях --> исполнитель : "P1659"
  фильм --> производящая_компания : "P1963"
  фильм --> кинооператор : "P1963"
  полученные_награды --> победитель : "P1659"
  фильм --> автор_слов : "P1963"
  полученные_награды --> за_работу : "P1659"
  жанр --> основная_тема : "P1659"
  автор_слов --> создатель : "P1659"
  фильм --> цвет : "P1963"
  фильм --> распространяется : "P1963"
  автор_слов --> композитор : "P1659"
  в_ролях --> актёр_озвучивания : "P1659"
  жанр --> форма_творческой_работы : "P1659"
  жанр --> формат_изображения : "P1659"
  фильм --> основная_тема : "P1963"
  фильм --> страна_происхождения : "P1963"
  распространяется --> хостинг : "P1659"
  распространяется --> распространение_произведения : "P1659"
  фильм --> место_съёмок : "P1963"
  фильм --> дата_публикации : "P1963"
  автор_слов --> автор : "P1659"
  фильм --> место_действия : "P1963"
  место_съёмок --> страна_происхождения : "P1659"
  фильм --> монтажёр : "P1963"
  полученные_награды --> номинирован-а-_на : "P1659"
  в_ролях --> записанный_участник : "P1659"
  фильм --> номинирован-а-_на : "P1963"
  создано_на_основе --> изображённый_объект : "P1659"
  фильм --> название : "P1963"
  место_съёмок --> изображённый_объект : "P1659"
  в_ролях --> играет_роль_персонажа : "P1659"
```

## Написание текстов

Для формирования текста использовался `LLM API Гигачат`. Ему посылались типизированные запросы в следующем порядке:
- Формирование заголовка
- Формирование более развёрнутого определения (на основе информации из `Wikidata`)
- Формирование подзаголовка
- Объяснение связи понятия этой страницы и другого

В каждом запросе указывалось что текст предназначается для 10-летнего ребёнка, указывался объём текста, прикладывались определения и их описания.

К сожалению, т.к. нейронная сеть с трудом справлялась со сложными запросами, было принято решение вставлять ссылки на другие страницы в подзаголовки.

## Выводы

- В процессе использования Гигачата столкнулись с проблемой сертификации, но быстро её решили.
- Основной сложностью было получение хороших ответов от `Гигачата`. Изначально планировалось передать ему задачу по созданию места для вставки ссылки, но это оказалось безрезультатным. Был реализован функционал для изменения понятий, имеющих глаголы или находящихся не в именительном падеже, но нейронная сеть также с этим не справилась.
- Был реализован функционал по созданию `PlantUML`-диаграммы на основе графа из `SPARQL`, но потом было определено что `Github` поддерживает `Mermaid` и перешли к нему. 

В будущем можно реализовать анализ текста через `pymorphy2`, использовать более сложную нейронную сеть для повышения качества ответов, а также добавить создание изображений для страниц через соответствующую генеративную нейросеть.