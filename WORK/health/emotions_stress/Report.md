# Отчет по лабораторной работе: KidBook - Травля (Буллинг)

## Состав команды

| ФИО                                | Роль и что делал                                                                                                | Оценка |
|------------------------------------|-----------------------------------------------------------------------------------------------------------------|--------|
| Андриянов Эрик Вячеславович М80-312Б-22 | Исследование Wikidata (SPARQL, визуализация), разработка скрипта для генерации текстов (GigaChat API + LangChain), написание отчета |        |
| Драновский Иван Петрович М80-312Б-22   | Концептуализация, построение онтологии (Markmap), разработка промптов, разработка скрипта для кросс-линковки (`pymorphy3`), написание отчета |        |
|                                               |        |

*Примечание: Оценки проставляются преподавателем.*

## Концептуализация предметной области

**Тема:** Здоровье -> Эмоции и стресс -> Травля (Буллинг)

**Процесс:**

1.  **Исследование источников:** Первым делом мы погрузились в существующие базы знаний, в первую очередь **Wikidata**. С помощью **SPARQL-запросов** и инструментов визуализации графов знаний (подобных [Metaphacts](https://metaphacts.com/) или [Wikidata Query Service](https://query.wikidata.org/) с опцией графа) мы изучили существующие понятия, связанные с "травлей" (Bullying, Q18579). Мы выявили ключевые подклассы (интернет-травля, травля в школе и т.д.) и связанные сущности (моббинг, агрессор, свидетель). Пример визуализации графа представлен ниже (скриншот из инструмента типа Metaphacts/Wikidata Visualization).

    ![Скриншот графа Wikidata для "Травля"](/2025_kidbook/WORK/health/emotions_stress/image.png)
2.  **Построение онтологии:** На основе изученных данных и требований (не менее 15 понятий) мы разработали концептуализацию нашей предметной области. Мы определили основные классы ("Травля", "Вид Травли", "Участник Травли", "Действие/Реакция") и связи между ними. Помимо иерархических связей (`является подклассом`), мы старались определить и горизонтальные связи, такие как `имеет участника`, `проявляется как`, `может привести к`, `противодействие`.

3.  **Визуализация:** Для наглядного представления онтологии мы использовали **Markmap.js**. Это позволило легко создать интерактивную ментальную карту из Markdown-разметки, включив в нее ID из Wikidata для ключевых понятий.

    ```markmap
    # Карта понятий: Травля (Буллинг)

    ## Травля (Буллинг) [Q18579]

    - **Виды травли** (`является подклассом`)
      - Травля в школе [Q1093944]
      - Интернет-травля (Кибербуллинг) [Q18583]
      - Физический буллинг [Q1856261]
      - Словесный буллинг [Q7920890]
      - Социальный буллинг <!-- ID сложнее найти -->

    - **Участники** (`имеет участника`)
      - Агрессор (Обидчик) [Q1934304]
      - Жертва (Пострадавший)
      - Свидетель [Q18570]

    - **Аспекты и отличия** (`имеет аспект`, `отличается от`)
      - Чувства жертвы
      - Отличие буллинга от ссоры

    - **Что делать? / Помощь** (`противодействие`, `рекомендация`)
      - Что делать, если обижают тебя?
      - Что делать, если видишь буллинг? (Роль свидетеля)
      - Кому рассказать о буллинге? (Взрослые помощники)
      - Как остановить буллинг? (Дружба и Уважение)

    - **Связанные понятия**
      - Моббинг [Q205384]
    ```

4.  **Список концептов:** Финальный список из 15 концептов был сохранен в файле `WORK/health/emotions_stress/concepts.json` в требуемом формате.

## Написание текстов

1.  **Выбор LLM:** Мы остановили свой выбор на **GigaChat**. Основные причины:
    *   **Доступность и лимиты:** GigaChat предоставлял достаточно щедрый бесплатный лимит на момент выполнения работы, что позволило нам экспериментировать с API без значительных затрат. "Халява, сэр!" - как говорится, отличный стимул для студенческих проектов.
    *   **Качество русского языка:** Модель хорошо справляется с генерацией текстов на русском языке, что было критично для нашей задачи.
    *   **Интеграция с LangChain:** Наличие готовой интеграции в популярной библиотеке `langchain-community` упростило программное взаимодействие с API.

2.  **Генерация через API:** Для повышения оценки и автоматизации процесса мы использовали **Python** и библиотеку **LangChain** для программного вызова GigaChat API. Был написан скрипт (`text_generator.py`), который:
    *   Читал список тем из `concepts.json`.
    *   Инициализировал клиент GigaChat через LangChain, используя ключ авторизации, вводимый безопасно через `getpass`.
    *   Использовал `PromptTemplate` и `LLMChain` для формирования запросов.
    *   Итерировал по списку тем, отправляя запросы к API с паузами (`time.sleep`), чтобы не превышать лимиты.
    *   Сохранял полученные тексты в соответствующие `.md` файлы в директории `KIDBOOK`, добавляя заголовок первого уровня.

3.  **Разработка промпта:** Ключевым моментом была разработка эффективного промпта. Мы использовали следующий шаблон:

    ```text
    Объясни для десятилетнего ребенка простыми словами, что такое "{topic}".

    Твой ответ будет использоваться для детской энциклопедии KidBook.
    Пожалуйста, оформи текст в формате Markdown. Используй:
    *   **Заголовки второго уровня (##)** для выделения важных подтем, если это уместно.
    *   **Списки (* или -)** для перечислений или шагов.
    *   **Выделение жирным шрифтом (**слово**)** для ключевых терминов или важных моментов.
    *   **Выделение курсивом (*слово*)** для определений или примеров.

    Сделай текст понятным, интересным и хорошо структурированным. Не используй заголовок первого уровня (#), так как он будет добавлен автоматически из названия темы.
    ```
    Этот промпт явно указывал на целевую аудиторию (10 лет), требуемый формат (Markdown) и давал конкретные рекомендации по структурированию.

4.  **Расстановка кросс-ссылок:** Для автоматической расстановки ссылок между статьями был разработан отдельный скрипт (`link_generator.py`).
    *   **Сбор данных:** Скрипт агрегировал информацию из всех `concepts.json` файлов в директории `WORK`.
    *   **Лемматизация:** Для учета различных форм слов (падежей, чисел) мы использовали библиотеку **`pymorphy3`**. Скрипт разделял концепты на однословные (для них применялась лемматизация) и многословные/сложные (для них использовался поиск по точному совпадению фразы).
    *   **Поиск и замена:** Скрипт обрабатывал каждый `.md` файл:
        *   Маскировал существующие Markdown-ссылки и блоки кода, чтобы избежать их повреждения.
        *   Сначала искал и заменял многословные/сложные термины (от длинных к коротким).
        *   Затем токенизировал оставшийся текст и искал однословные термины по их леммам, создавая ссылки с использованием *оригинального* слова из текста.
        *   Рассчитывал корректные **относительные пути** между файлами с помощью `os.path.relpath`.
        *   Снимал маскировку и перезаписывал файл (при наличии изменений и если не был включен режим `--dry-run`).
    *   **Обработка падежей:** Использование `pymorphy3` позволило частично решить проблему падежей для однословных терминов (например, найти "свидетеля", если тема "Свидетель").

## Выводы

**Успехи:**

*   Удалось успешно интегрировать данные из **Wikidata** в процесс концептуализации.
*   Создана онтология предметной области, включающая более 15 понятий и разные типы связей, визуализированная с помощью **Markmap**.
*   Реализована **автоматическая генерация текстов** для всех понятий с использованием **GigaChat API** и библиотеки **LangChain**.
*   Разработан скрипт для **автоматической расстановки кросс-ссылок**, использующий **лемматизацию (`pymorphy3`)** для повышения точности связывания в русском языке.

**Сложности и решения:**

1.  **Точность ссылок и падежи:** Несмотря на использование `pymorphy3`, автоматическая расстановка ссылок не идеальна. Некоторые формы слов могли быть пропущены, или, наоборот, могли быть созданы некорректные ссылки (например, слово используется в другом контексте).
    *   *Решение:* Комбинированный подход (лемматизация + точное совпадение), сортировка тем по длине, проверка на самоссылки. Требуется **ручной контроль** результатов.
2.  **Маскировка Markdown:** Обеспечить 100% надежную маскировку всех возможных конструкций Markdown (особенно вложенных) при замене текста – нетривиальная задача.
    *   *Решение:* Использование регулярных выражений для основных конструкций (ссылки, код). Возможны ошибки на сложных случаях.
3.  **Качество LLM-генерации:** Хотя GigaChat показал хорошие результаты, иногда тексты требовали ручной доработки для улучшения стиля, фактологической точности или соответствия возрасту. Форматирование Markdown не всегда было идеальным.
    *   *Решение:* Тщательный подбор промпта, готовность к **постредактированию**.
4.  **Поиск в Wikidata:** Найти подходящие и точные QID для всех концептов (особенно для абстрактных или составных, вроде "Чувства жертвы") было сложно.
    *   *Решение:* Фокусировка на ключевых понятиях, использование поиска по синонимам на разных языках, принятие того, что не для всего есть прямой аналог.

**Возможные улучшения:**

*   **Улучшение скрипта линковки:** Использовать более продвинутые NLP-методы для идентификации мест для ссылок (не только по ключевым словам/леммам, но и по семантической близости). Внедрить более надежный парсер Markdown.
*   **Интеграция изображений:** Добавить автоматический поиск (например, через API поисковиков или специализированные сервисы) и вставку релевантных изображений в статьи.
*   **Более глубокая интеграция с Wikidata:** Использовать SPARQL-запросы не только для концептуализации, но и для извлечения фактов (например, дат, определений, связей), которые можно было бы включать в промпты для LLM для более фактологически точной генерации.
*   **Интерактивность:** Добавить тесты или викторины к статьям.

В целом, работа позволила на практике познакомиться с методами представления знаний, возможностями современных LLM и задачами автоматической обработки текста, показав как сильные стороны этих инструментов, так и существующие ограничения.
